{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4549fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pyccl as ccl\n",
    "import healpy as hp\n",
    "import pymaster as nmt\n",
    "import matplotlib.pyplot as plt\n",
    "import libconf\n",
    "# from scipy.integrate import simps\n",
    "from scipy.integrate import simpson\n",
    "from astropy.io import fits\n",
    "\n",
    "import camb\n",
    "from camb import model, initialpower\n",
    "from __future__ import print_function\n",
    "import treecorr\n",
    "import fitsio\n",
    "import time\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import camb\n",
    "from camb import model\n",
    "from camb.sources import SplinedSourceWindow\n",
    "from scipy.special import erf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "csm = {'omega_M': 0.31,\n",
    "       'omega_B': 0.05,\n",
    "       'omega_L': 1-0.31,\n",
    "       'h': 0.6774,\n",
    "       'w': -1.0,\n",
    "       'ns': 0.967,\n",
    "       'sigma_8': np.nan(),\n",
    "       'As': 2.142e-9}\n",
    "\n",
    "def get_pk(csm, z_in):\n",
    "    \"\"\"\n",
    "    get_pk(csm, z_in)\n",
    "    Calculate the matter power spectrum, $\\sigma_8$ and $f$ values, given a cosmological model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csm : dictionary - TO BE UPDATED HERE, sigma_8 value does not matter\n",
    "        Keys must be ['omega_M', 'omega_B', 'omega_L', 'h', 'w', 'ns', 'sigma_8', 'As']\n",
    "        encoding the values for[matter energy density, baryon energy density, dark energy energy density, \n",
    "            Hubble constant, dark energy constant, $\\sigma_8$, primordial amplitude]\n",
    "    z_in : array-like\n",
    "        Array of redshifts to calculate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    csm : With the $\\sigma_8$ value updated, but otherwise the same\n",
    "    kh : $k$ values (h units)\n",
    "    pk : $P(k)$ values (h units)\n",
    "    f : \n",
    "    \"\"\"\n",
    "    #Set up the fiducial cosmology\n",
    "    pars = camb.CAMBparams()\n",
    "    #Set cosmology\n",
    "    pars.set_cosmology(H0=csm['h']*100, ombh2=csm['omega_B']*csm['h']**2, omch2=(1-csm['omega_M'])*csm['h']**2,omk=0,mnu=0)\n",
    "    pars.set_dark_energy() #LCDM (default)\n",
    "    pars.InitPower.set_params(ns=csm['ns'], r=0, As=csm['As'])\n",
    "    pars.set_matter_power(redshifts=[z_in], kmax=2.0)\n",
    "    pars.NonLinear = model.NonLinear_none\n",
    "    results = camb.get_results(pars)\n",
    "    kh, z, pk = results.get_matter_power_spectrum(minkh=1e-4, maxkh=2.0, npoints = 500)\n",
    "    \n",
    "    csm['sigma_8'] = results.get_sigma8()\n",
    "    f = results.get_fsigma8()/csm['sigma_8']\n",
    "    \n",
    "    return csm, kh, pk[0], f[0]\n",
    "\n",
    "def dndz_des_alonso(zi, amp=22.357, alpha=1.044, z0=0.568, beta=1.742):\n",
    "    \"\"\"\n",
    "    in degâ»2\n",
    "    \"\"\"\n",
    "    return amp*(zi/z0)**alpha*np.exp(-(zi/z0)**beta)*3600/100\n",
    "\n",
    "\n",
    "def _gen_random_catalogue_theta(RA_min, RA_max, DEC_min, DEC_max, Npoints, seed=None):\n",
    "    # Code from Pedro Fanha\n",
    "    # generates a region populated with Npoints random points\n",
    "    # RA_min, RA_max, DEC_min, DEC_max are floats (limits of square region)\n",
    "    # Npoints integer (number of points to generate in the random)\n",
    "    # seed (optional, set it to generate a specific distribution of points)\n",
    "    \n",
    "    # https://math.stackexchange.com/questions/711594/uniform-sampling-from-part-of-sphere-surface\n",
    "    # RA in [0, 360[, DEC in [-90, 90[\n",
    "\n",
    "    # TO DO: are there any built in functions in scipy stats to do this (inverse CDF?)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # select u, v in region of angles that I want\n",
    "    phi_min = RA_min/180*np.pi\n",
    "    phi_max = RA_max/180*np.pi\n",
    "    \n",
    "    u_min = phi_min/(2*np.pi)\n",
    "    u_max = phi_max/(2*np.pi)\n",
    "\n",
    "    # calculations take phi -> ra (0 to 2pi) ==> u\n",
    "    # and theta -> dec (0 to pi) ==> v + theta = 0 corresponds to z axis, declination starts at equator\n",
    "    theta_min_2 = (90 - DEC_min)/180*np.pi\n",
    "    theta_max_2 = (90 - DEC_max)/180*np.pi\n",
    "    \n",
    "    v_min = (np.cos(theta_min_2) + 1)/2\n",
    "    v_max = (np.cos(theta_max_2) + 1)/2\n",
    "\n",
    "    u = u_min + (u_max - u_min)*rng.uniform(0, 1, size=Npoints)\n",
    "    v = v_min + (v_max - v_min)*rng.uniform(0, 1, size=Npoints)\n",
    "\n",
    "    # transform from u, v to angles phi, theta and then to RA, DEC (convert to degree)\n",
    "    ra = 2*np.pi*u\n",
    "    ra_deg = ra/np.pi*180\n",
    "    dec = np.pi/2 - np.arccos(2*v - 1)\n",
    "    dec_deg = dec/np.pi*180\n",
    "\n",
    "    return pd.DataFrame({'RA': ra_deg % 360, 'DEC': dec_deg})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82489232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_colore(csm, k_h, pk_h, n_grid, n_bins, zs, dndz=0, tz=0, bias):\n",
    "    \"\"\"\n",
    "    make_colore(csm, n_grid, zs, dndz=0, tz=0, bias)\n",
    "    Create desired CoLoRe simualtions (either photometric catalog or temperature maps)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csm : dictionary\n",
    "        Keys must be ['omega_M', 'omega_B', 'omega_L', 'h', 'w', 'ns', 'sigma_8', 'As']\n",
    "        encoding the values for[matter energy density, baryon energy density, dark energy energy density, \n",
    "            Hubble constant, dark energy constant, $\\sigma_8$, primordial amplitude]\n",
    "    k_h : array-like\n",
    "        Range of $k$ (in $h$ units) values for which the matter power spectrum is determined\n",
    "    pk : array-like\n",
    "        Power spectrum values for the $k$ values\n",
    "    n_grid : integer, power of 2\n",
    "        Resolution of the simulation\n",
    "    n_bins : positive integer\n",
    "        Number of redshift bins to separate simulation in.\n",
    "    zs : array-like\n",
    "        Array of values of redshift to encompass in the simulation.\n",
    "    dndz : array-like, optional, default = 0\n",
    "        Array to be used if goal is phometric galaxy catalog. \n",
    "        If used, must have the same size as 'zs' and contain the galaxy distribution function.\n",
    "    tz :  : array-like, optional, default = 0\n",
    "        Array to be used if goal is temperature maps. \n",
    "        If used, must have the same size as 'zs' and contain the background temperature data.\n",
    "    bias : array-like\n",
    "        Must have same size as zs. Contains the observation bias function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The desired map in a sub-directory. If photometry catalog, '\\sources', if H1IM, '\\maps'\n",
    "    \"\"\"\n",
    "\n",
    "    config = {}\n",
    "    \n",
    "    if dndz!=0:\n",
    "        dirname_out = 'sources'\n",
    "        np.savetxt(f'{dirname_out}/dndz.txt', np.transpose([zs, dndz]))\n",
    "\n",
    "        config['srcs1'] = {'nz_filename': f'{dirname_out}/dndz.txt',\n",
    "                           'bias_filename': f'{dirname_out}/bias.txt',\n",
    "                           'include_lensing': True,\n",
    "                           'store_skewers': False}\n",
    "    \n",
    "    if tz!=0:\n",
    "        dirname_out = 'maps'\n",
    "        np.savetxt(f'{dirname_out}/tz.txt', np.transpose([zs, tz]))\n",
    "        nu_ref = 1420.\n",
    "        nu0 = nu_ref / (1+float(zs[-1]))\n",
    "        nu1 = nu_ref / (1+float(zs[0]))\n",
    "        nu_arr = np.linspace(nu0, nu1, n_bins+1)\n",
    "        np.savetxt(f'{dirname_out}/nuTable.txt', np.transpose([nu_arr[:-1], nu_arr[1:]]))\n",
    "        \n",
    "        config['imap1'] = {'tbak_filename': f'{dirname_out}/tz.txt',\n",
    "                           'bias_filename': f'{dirname_out}/bias.txt',\n",
    "                           'freq_list': f'{dirname_out}/nuTable.txt',\n",
    "                           'freq_rest': nu_ref,\n",
    "                           'nside': n_side}\n",
    "\n",
    "    np.savetxt(f'{dirname_out}/bias.txt', np.transpose([zs, bias]))\n",
    "    np.savetxt(f'{dirname_out}/pk.txt', np.transpose([k_h, pk_h]))\n",
    "\n",
    "    if zs[0]>0:\n",
    "        z_min = zs[0]\n",
    "    else:\n",
    "        z_min=0.001\n",
    "    \n",
    "    config['global'] = {'prefix_out': dirname_out + '/colore',\n",
    "                        'output_format': 'FITS',\n",
    "                        'output_density': True,\n",
    "                        'pk_filename': f'{dirname_out}/pk.txt',\n",
    "                        'z_min': float(z_min),\n",
    "                        'z_max': float(zs[-2]),\n",
    "                        'seed': 1000,\n",
    "                        'write_pred': False,\n",
    "                        'just_write_pred': False}\n",
    "    config['field_par'] = {'r_smooth': 1.,\n",
    "                        'smooth_potential': True,\n",
    "                        'n_grid': n_grid,\n",
    "                        'dens_type': 1,\n",
    "                        'lpt_buffer_fraction': 0.6,\n",
    "                        'lpt_interp_type': 1,\n",
    "                        'output_lpt': 0}\n",
    "    config['cosmo_par'] = csm\n",
    "    with open(f'{dirname_out}/params.cfg', 'w') as configfile:\n",
    "        libconf.dump(config, configfile)\n",
    "\n",
    "    os.system(f'../CoLoRe/CoLoRe {dirname_out}/params.cfg > {dirname_out}/log.txt')\n",
    "    f = open(f'{dirname_out}/log.txt', 'r')\n",
    "    print(f.read())\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def make_treecorr_sources(file_path):\n",
    "    \"\"\"\n",
    "    make_treecorr_sources(file_path)\n",
    "    Calculates the angular correlation function of the source map provided\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : string\n",
    "        Path to CoLoRe source map\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        r : array-like\n",
    "            Array of separation values\n",
    "        xi : array-like\n",
    "            Angular correlation function values for the 'r' separations\n",
    "        varxi : array-like\n",
    "            Variance of the correlation function values\n",
    "    \"\"\"\n",
    "    cat = fits.open(file_path)[1].data\n",
    "\n",
    "    cat_sources = treecorr.Catalog(ra=cat[\"RA\"], dec=cat[\"DEC\"], \n",
    "                                   ra_units='deg', dec_units='deg')\n",
    "    \n",
    "    DD = treecorr.NNCorrelation(min_sep=0.5, max_sep=10, nbins=50, sep_units='degrees')\n",
    "    RR = treecorr.NNCorrelation(min_sep=0.5, max_sep=10, nbins=50, sep_units='degrees')\n",
    "    DR = treecorr.NNCorrelation(min_sep=0.5, max_sep=10, nbins=50, sep_units='degrees')\n",
    "    RD = treecorr.NNCorrelation(min_sep=0.5, max_sep=10, nbins=50, sep_units='degrees')\n",
    "    DD.process(cat_sources)\n",
    "\n",
    "    n_pts_rand = int( 5 * len (cat[\"RA\"]))\n",
    "\n",
    "    df_sky_pos = _gen_random_catalogue_theta( RA_min=0, RA_max=360, DEC_min=-90, DEC_max=90, Npoints=n_pts_rand, seed=7+15*10 )\n",
    "    cat_random = treecorr.Catalog(ra=df_sky_pos[\"RA\"], dec=df_sky_pos[\"DEC\"], \n",
    "                                  ra_units='degrees', dec_units='degrees')\n",
    "    RR.process(cat_random)\n",
    "    DR.process(cat_sources, cat_random)\n",
    "    RD.process(cat_random, cat_sources)\n",
    "\n",
    "    xi, varxi  = DD.calculateXi(rr=RR, dr=DR, rd=RD)\n",
    "\n",
    "    r = np.exp(DD.meanlogr)\n",
    "\n",
    "    return r, xi, varxi\n",
    "\n",
    "def make_treecorr_maps(file_path):\n",
    "    \"\"\"\n",
    "    make_treecorr_maps(file_path)\n",
    "    Calculates the angular correlation function of the temperature map provided\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : string\n",
    "        Path to CoLoRe temperature map\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        r : array-like\n",
    "            Array of separation values\n",
    "        xi : array-like\n",
    "            Angular correlation function values for the 'r' separations\n",
    "        varxi : array-like\n",
    "            Variance of the correlation function values\n",
    "    \"\"\"\n",
    "    cat = fits.open(file_path)[1].data\n",
    "    mean = np.average(cat)\n",
    "    delta = cat-mean\n",
    "\n",
    "    nside = hp.get_nside(delta)\n",
    "    npix = hp.get_map_size(delta)\n",
    "    pixel_indices = np.arange(npix)\n",
    "    theta, phi = hp.pix2ang(nside, pixel_indices)\n",
    "    ra = np.degrees(phi)\n",
    "    dec = 90.0 - np.degrees(theta)\n",
    "\n",
    "    cat_imap = treecorr.Catalog(ra=ra, dec=dec, k=delta, \n",
    "                                    ra_units='deg', dec_units='deg')\n",
    "    \n",
    "    KK = treecorr.KKCorrelation(min_sep=0.5, max_sep=10, nbins=50, sep_units='degrees')\n",
    "    KK.process(cat_imap)\n",
    "\n",
    "    r = np.exp(KK.meanlogr)\n",
    "    xi = KK.xi\n",
    "    varxi = KK.varxi\n",
    "\n",
    "    return r, xi, varxi\n",
    "\n",
    "def make_treecorr_corr(photo_map_path, temp_map_path):\n",
    "    \"\"\"\n",
    "    make_treecorr_corr(photo_map_path, temp_map_path)\n",
    "    Calculates the angular cross-correlation function of the source and temperature maps provided\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    photo_map_path : string\n",
    "        Path to CoLoRe source map\n",
    "    temp_map_path : string\n",
    "        Path to CoLoRe temperature map\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        r : array-like\n",
    "            Array of separation values\n",
    "        xi : array-like\n",
    "            Angular correlation function values for the 'r' separations\n",
    "        varxi : array-like\n",
    "            Variance of the correlation function values    \n",
    "    \"\"\"\n",
    "\n",
    "    imap = hp.read_map(temp_map_path)\n",
    "    med_T=np.average(imap)\n",
    "    delta=imap-med_T\n",
    "    nside = hp.get_nside(delta)\n",
    "    npix = hp.get_map_size(delta)\n",
    "    pixel_indices = np.arange(npix)\n",
    "    theta, phi = hp.pix2ang(nside, pixel_indices)\n",
    "    ra = np.degrees(phi)\n",
    "    dec = 90.0 - np.degrees(theta)\n",
    "\n",
    "    catalog_imap = treecorr.Catalog(ra=ra, dec=dec, k=delta, \n",
    "                                    ra_units='deg', dec_units='deg')\n",
    "\n",
    "    cat = fits.open(photo_map_path)[1].data\n",
    "    catalog_sources = treecorr.Catalog(ra=cat[\"RA\"], dec=cat[\"DEC\"], \n",
    "                                       ra_units='deg', dec_units='deg')\n",
    "\n",
    "\n",
    "    NK = treecorr.NKCorrelation(min_sep=0.5, max_sep=10, nbins=50, sep_units='degrees')\n",
    "    NK.process(catalog_sources, catalog_imap)\n",
    "\n",
    "    xi, varxi = NK.calculateXi()\n",
    "\n",
    "    r = np.exp(NK.meanlogr)\n",
    "\n",
    "    return r, xi, varxi\n",
    "\n",
    "\n",
    "def make_camb(csm, lmax, cross = False, zs, Ws, bias):\n",
    "    \"\"\"\n",
    "    make_camb(csm, lmax, zs, Ws, bias, cross = False)\n",
    "    Create the theoretical $C_\\ell$ values for a given cosmology and set of space\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csm : dictionary\n",
    "        Keys must be ['omega_M', 'omega_B', 'omega_L', 'h', 'w', 'ns', 'sigma_8', 'As']\n",
    "        encoding the values for[matter energy density, baryon energy density, dark energy energy density, \n",
    "            Hubble constant, dark energy constant, $\\sigma_8$, primordial amplitude]\n",
    "    lmax : integer\n",
    "        Maximum scale to consider\n",
    "    cross : boolean, default = False\n",
    "        If False, will perform auto-correlation, and 'zs', 'Ws' and 'bias' must be 1D-arrays.\n",
    "        If True, will perform cross-correlation, and 'zs', 'Ws' and 'bias' must be 2D-arrays.\n",
    "    zs : array-like\n",
    "        Redshift values over which to calculate the power spectrum\n",
    "    Ws : array-like\n",
    "        Mask on the detection\n",
    "    bias : array-like\n",
    "        Bias observation function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ls : array-like\n",
    "        List of $\\ell$ values, [2:lmax+1]\n",
    "    cls : array-like\n",
    "        $C_\\ell$ values\n",
    "    \"\"\"\n",
    "\n",
    "    pars = camb.CAMBparams()\n",
    "    pars.set_cosmology(H0=csm['h']*100, ombh2=csm['omega_B']*csm['h']**2, omch2=(csm['omega_M']-csm['omega_B'])*csm['h']**2)\n",
    "    pars.InitPower.set_params(As=csm['As'], ns=csm['ns'])\n",
    "    pars.set_for_lmax(lmax, lens_potential_accuracy=1)\n",
    "    pars.Want_CMB = False\n",
    "    pars.NonLinear = model.NonLinear_both\n",
    "\n",
    "    if cross:\n",
    "        pars.SourceWindows = [SplinedSourceWindow(z = zs[0], W = Ws[0], bias_z = bias[0]),\n",
    "                              SplinedSourceWindow(z = zs[1], W = Ws[1], bias_z = bias[1])]\n",
    "    else:\n",
    "        pars.SourceWindows = [SplinedSourceWindow(z = zs, W = Ws, bias_z = bias)]\n",
    "\n",
    "    results = camb.get_results(pars)\n",
    "    cls = results.get_source_cls_dict(raw_cl=True)\n",
    "    ls = np.arange(2, lmax+1)\n",
    "\n",
    "    return ls, cls\n",
    "\n",
    "def make_w_theta(csm, ls, cls, theta):\n",
    "    \"\"\"\n",
    "    make_w_theta(csm, ls, cls, theta)\n",
    "    Determine theoretical angular correlation function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csm : dictionary\n",
    "        Keys must be ['omega_M', 'omega_B', 'omega_L', 'h', 'w', 'ns', 'sigma_8', 'As']\n",
    "        encoding the values for[matter energy density, baryon energy density, dark energy energy density, \n",
    "            Hubble constant, dark energy constant, $\\sigma_8$, primordial amplitude]\n",
    "    ls : array-like\n",
    "        List of $\\ell$ values\n",
    "    cls : array-like\n",
    "        Corresponding list of **treated** $C_\\ell$ values, meaning they must aleady include shot noise terms, for example.\n",
    "    theta : array-like\n",
    "        Array of theta separation values to examine\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wtheta : array-like\n",
    "        Angular correlation function values\n",
    "    \"\"\"\n",
    "\n",
    "    cosmo = ccl.Cosmology(Omega_c=csm['omega_M']-csm['omega_B'],\n",
    "                      Omega_b=csm['omega_B'],\n",
    "                      h=csm['h'],\n",
    "                      sigma8=csm['sigma_8'],\n",
    "                      n_s=csm['ns'],\n",
    "                      transfer_function='eisenstein_hu')\n",
    "\n",
    "    wtheta = ccl.correlation(cosmo, ell=ls, C_ell=cls, \n",
    "                         theta=theta, type='NN', method='FFTLog')\n",
    "    \n",
    "    return wtheta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
